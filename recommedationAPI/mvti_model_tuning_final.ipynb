{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82EboxLyIBZM"
      },
      "source": [
        "**데이터 로드**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EgspLfqKCMR2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.9.0) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (2.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (0.31.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.9.0) (24.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (1.26.4)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (1.64.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (1.16.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.9.0) (4.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (3.11.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.9.0) (65.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.9.0) (0.43.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.32.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.29.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (5.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.0.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-text==2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.0)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-text==2.9.0) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-text==2.9.0) (0.16.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.9.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.31.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.64.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (65.5.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (24.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.16.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.26.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (4.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.6.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-hub>=0.8.0->tensorflow-text==2.9.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.43.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.0.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.29.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (5.3.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2024.2.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow-text==2.9.0) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow==2.9.0\n",
        "%pip install tensorflow-text==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
            "     ---------------------------------------- 0.0/8.3 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.2/8.3 MB 6.1 MB/s eta 0:00:02\n",
            "     -- ------------------------------------- 0.6/8.3 MB 7.2 MB/s eta 0:00:02\n",
            "     --- ------------------------------------ 0.7/8.3 MB 5.2 MB/s eta 0:00:02\n",
            "     ----- ---------------------------------- 1.1/8.3 MB 6.4 MB/s eta 0:00:02\n",
            "     ------- -------------------------------- 1.6/8.3 MB 7.1 MB/s eta 0:00:01\n",
            "     --------- ------------------------------ 1.9/8.3 MB 7.2 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 2.3/8.3 MB 7.2 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 2.7/8.3 MB 7.3 MB/s eta 0:00:01\n",
            "     -------------- ------------------------- 3.1/8.3 MB 7.5 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 3.5/8.3 MB 7.8 MB/s eta 0:00:01\n",
            "     ------------------ --------------------- 3.9/8.3 MB 7.8 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 4.2/8.3 MB 7.7 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 4.7/8.3 MB 7.9 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 5.1/8.3 MB 8.0 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 5.6/8.3 MB 8.1 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 6.0/8.3 MB 8.1 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 6.0/8.3 MB 8.2 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 6.4/8.3 MB 7.7 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 6.8/8.3 MB 7.7 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 7.1/8.3 MB 7.7 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 7.4/8.3 MB 7.7 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 7.8/8.3 MB 7.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  8.2/8.3 MB 7.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  8.3/8.3 MB 7.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 8.3/8.3 MB 7.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.2.2) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.0\n",
            "    Uninstalling scikit-learn-1.5.0:\n",
            "      Successfully uninstalled scikit-learn-1.5.0\n",
            "Successfully installed scikit-learn-1.2.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install scikit-learn==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sdJ9O2KgCUnA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from itertools import product\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "parE5sWsI9Vg"
      },
      "outputs": [],
      "source": [
        "# 시작 방법을 'forkserver'로 설정\n",
        "multiprocessing.set_start_method('forkserver', force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8ZBbpNLC8IW"
      },
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "mbti = pd.read_csv('resource/MBTI 500.csv')\n",
        "movies = pd.read_csv('resource/movie_meta_data_final.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model_path = 'resource/labse_model.h5'\n",
        "labse_model = keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYzzIVOOIjyB"
      },
      "source": [
        "**LaBSE 모델 로드 및 임베딩 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k6xuXuRDAFs"
      },
      "outputs": [],
      "source": [
        "# LaBSE 모델 로드\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")\n",
        "\n",
        "# 텍스트를 고차원 벡터로 인코딩하는 모델 구성\n",
        "sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
        "encoder_inputs = preprocessor(sentences)\n",
        "sentence_representation = encoder(encoder_inputs)[\"pooled_output\"]\n",
        "normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)\n",
        "labse_model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
        "labse_model.compile()\n",
        "\n",
        "# 임베딩을 생성하는 함수\n",
        "def embed_sentence(sentence):\n",
        "    return labse_model(tf.constant([sentence]))[0].numpy().astype(np.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 임베딩을 생성하는 함수\n",
        "def embed_sentence(sentence):\n",
        "    return labse_model(tf.constant([sentence]))[0].numpy().astype(np.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mbti_embeddings_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxajJxF-Itcb"
      },
      "source": [
        "**영화 데이터 전처리 및 임베딩 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8EPgEl-DCgy"
      },
      "outputs": [],
      "source": [
        "# 병렬 처리를 이용하여 임베딩 생성\n",
        "def parallel_embedding(texts):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        embeddings = list(executor.map(embed_sentence, texts))\n",
        "    return np.array(embeddings).astype(np.float64)\n",
        "\n",
        "# MBTI 임베딩 병렬 처리\n",
        "mbti_posts = mbti.groupby('type')['posts'].apply(lambda posts: ' '.join(posts)).tolist()\n",
        "mbti_embeddings = parallel_embedding(mbti_posts)\n",
        "mbti_index = mbti.groupby('type').groups.keys()\n",
        "mbti_embeddings_dict = dict(zip(mbti_index, mbti_embeddings))\n",
        "\n",
        "# 한국어 영화 줄거리 임베딩 병렬 처리\n",
        "movie_texts = movies['overview'].tolist()\n",
        "movie_embeddings = parallel_embedding(movie_texts)\n",
        "movie_index = movies['name'].tolist()\n",
        "movie_embeddings_dict = dict(zip(movie_index, movie_embeddings))\n",
        "\n",
        "# 영화 장르 원핫 인코딩\n",
        "genres = movies['genres'].str.get_dummies(sep=',')\n",
        "cbf_model_input = np.hstack([genres.values, movies['star_avg'].values.reshape(-1, 1)])\n",
        "cbf_scaler = StandardScaler()\n",
        "cbf_model_input_scaled = cbf_scaler.fit_transform(cbf_model_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('mbti_embeddings_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(mbti_embeddings_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('movie_embeddings_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(movie_embeddings_dict, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzfpxqgFI1tR"
      },
      "source": [
        "**CBF 모델 하이퍼파라미터 최적화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIoqT4AwDJrj"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 그리드 설정 -> 필요 없음 \n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5, 6, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# 그리드 서치 설정\n",
        "gbm = GradientBoostingRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# 학습 데이터와 평가 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(cbf_model_input_scaled, movies['star_avg'].values, test_size=0.2, random_state=42)\n",
        "\n",
        "# 그리드 서치 수행\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델 출력\n",
        "best_gbm = grid_search.best_estimator_\n",
        "print(f'Best GBM Model: {best_gbm}')\n",
        "\n",
        "# 파라미터 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.external.joblib as extjoblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'resource/mbti_embeddings_dict.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "with open(file_path, 'rb') as f:\n",
        "\tdata = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 최적의 모델 로드\n",
        "best_gbm = joblib.load('resource/best_gbm_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EqV4TOJCXt"
      },
      "source": [
        "**MBTI 기반 추천, 선호 영화 유사도 기반 추천, 결합 추천 시스템 정의**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDAe7FMMJBAq"
      },
      "outputs": [],
      "source": [
        "# 영화와 MBTI 유형 간의 유사도 계산 함수\n",
        "def calculate_similarity(movie_embedding, user_embedding):\n",
        "    from numpy import dot\n",
        "    from numpy.linalg import norm\n",
        "    return dot(movie_embedding, user_embedding) / (norm(movie_embedding) * norm(user_embedding))\n",
        "\n",
        "# 1. MBTI 임베딩 기반 추천\n",
        "def recommend_movies_by_mbti(user_embedding, movie_embeddings_dict, top_n=100):\n",
        "    recommended_movies = []\n",
        "    for movie, embedding in movie_embeddings_dict.items():\n",
        "        similarity = calculate_similarity(embedding, user_embedding)\n",
        "        recommended_movies.append((movie, similarity))\n",
        "    recommended_movies = sorted(recommended_movies, key=lambda x: x[1], reverse=True)\n",
        "    return recommended_movies[:top_n]\n",
        "\n",
        "# 2. 선호 영화 유사도 기반 추천\n",
        "def recommend_similar_movies(preferred_movies, movie_embeddings_dict, top_n=100):\n",
        "    similar_movies = {}\n",
        "    for movie in preferred_movies:\n",
        "        movie_embedding = movie_embeddings_dict[movie]\n",
        "        for other_movie, embedding in movie_embeddings_dict.items():\n",
        "            if other_movie not in preferred_movies:\n",
        "                similarity = calculate_similarity(embedding, movie_embedding)\n",
        "                if other_movie not in similar_movies:\n",
        "                    similar_movies[other_movie] = 0\n",
        "                similar_movies[other_movie] += similarity\n",
        "    similar_movies = sorted(similar_movies.items(), key=lambda x: x[1], reverse=True)\n",
        "    return similar_movies[:top_n]\n",
        "\n",
        "# MSE 계산 함수\n",
        "def calculate_mse(recommendations, movies, model, cbf_model_input_scaled):\n",
        "    movie_indices = [movies[movies['name'] == movie].index[0] for movie in recommendations]\n",
        "    movie_features = cbf_model_input_scaled[movie_indices]\n",
        "    true_ratings = movies.loc[movie_indices, 'star_avg'].values\n",
        "    predicted_ratings = model.predict(movie_features)\n",
        "    mse = mean_squared_error(true_ratings, predicted_ratings)\n",
        "    return mse\n",
        "\n",
        "# 결합 추천 시스템\n",
        "def recommend_movies_combined(user_embedding, preferred_movies, movie_embeddings_dict, model,\n",
        "                              weight_mbti=0.3, weight_similar=0.3, weight_model=0.4, top_n=20):\n",
        "    mbti_recommendations = recommend_movies_by_mbti(user_embedding, movie_embeddings_dict, top_n=100)\n",
        "    similar_movie_recommendations = recommend_similar_movies(preferred_movies, movie_embeddings_dict, top_n=100)\n",
        "\n",
        "    combined_recommendations = {}\n",
        "\n",
        "    for movie, score in mbti_recommendations:\n",
        "        if movie not in combined_recommendations:\n",
        "            combined_recommendations[movie] = 0\n",
        "        combined_recommendations[movie] += weight_mbti * score\n",
        "\n",
        "    for movie, score in similar_movie_recommendations:\n",
        "        if movie not in combined_recommendations:\n",
        "            combined_recommendations[movie] = 0\n",
        "        combined_recommendations[movie] += weight_similar * score\n",
        "\n",
        "    movie_indices = [movies[movies['name'] == movie].index[0] for movie in combined_recommendations.keys()]\n",
        "    if movie_indices:\n",
        "        movie_features = cbf_model_input_scaled[movie_indices]\n",
        "        model_scores = model.predict(movie_features).flatten()\n",
        "\n",
        "        for movie, model_score in zip(combined_recommendations.keys(), model_scores):\n",
        "            combined_recommendations[movie] += weight_model * model_score\n",
        "\n",
        "    filtered_recommendations = {movie: score for movie, score in combined_recommendations.items()\n",
        "                                if movies.loc[movies['name'] == movie, 'star_avg'].values[0] >= 3.3}\n",
        "\n",
        "    final_recommendations = sorted(filtered_recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [movie for movie, _ in final_recommendations[:top_n]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3LvaMthJGPp"
      },
      "source": [
        "**최적의 가중치 찾기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhP4jPGiJHtY"
      },
      "outputs": [],
      "source": [
        "# 예시 사용자 입력 데이터\n",
        "new_user_mbti = \"INTP\"\n",
        "new_user_preferred_movies = [\"해리포터와 불의 잔\", \"스파이더맨: 노 웨이 홈\"]\n",
        "\n",
        "# 예시 사용자 임베딩 생성 (MBTI 임베딩 사용)\n",
        "new_user_embedding = mbti_embeddings_dict[new_user_mbti]\n",
        "\n",
        "weight_combinations = list(product([0.1, 0.2, 0.3, 0.4, 0.5], repeat=3))\n",
        "weight_combinations = [weights for weights in weight_combinations if sum(weights) == 1.0]\n",
        "\n",
        "best_weights = None\n",
        "best_mse = float('inf')\n",
        "\n",
        "for weights in weight_combinations:\n",
        "    weight_mbti, weight_similar, weight_model = weights\n",
        "    combined_recommendations = recommend_movies_combined(new_user_embedding, new_user_preferred_movies, movie_embeddings_dict,\n",
        "                                                         best_gbm, weight_mbti=weight_mbti, weight_similar=weight_similar, weight_model=weight_model)\n",
        "    mse = calculate_mse(combined_recommendations, movies, best_gbm, cbf_model_input_scaled)\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_weights = weights\n",
        "\n",
        "print(f'Best Weights: {best_weights}, Best MSE: {best_mse}')\n",
        "\n",
        "best_weight_mbti, best_weight_similar, best_weight_model = best_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e72nuulxJKJY"
      },
      "source": [
        "**최적화된 결합 추천 시스템 실행**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rq4q8NSJJdU"
      },
      "outputs": [],
      "source": [
        "# 3. 최적화된 결합 추천 시스템\n",
        "def recommend_movies_combined_optimized(user_embedding, preferred_movies, movie_embeddings_dict, model,\n",
        "                                        weight_mbti=best_weight_mbti, weight_similar=best_weight_similar, weight_model=best_weight_model, top_n=20):\n",
        "    mbti_recommendations = recommend_movies_by_mbti(user_embedding, movie_embeddings_dict, top_n=100)\n",
        "    similar_movie_recommendations = recommend_similar_movies(preferred_movies, movie_embeddings_dict, top_n=100)\n",
        "\n",
        "    combined_recommendations = {}\n",
        "\n",
        "    for movie, score in mbti_recommendations:\n",
        "        if movie not in combined_recommendations:\n",
        "            combined_recommendations[movie] = 0\n",
        "        combined_recommendations[movie] += weight_mbti * score\n",
        "\n",
        "    for movie, score in similar_movie_recommendations:\n",
        "        if movie not in combined_recommendations:\n",
        "            combined_recommendations[movie] = 0\n",
        "        combined_recommendations[movie] += weight_similar * score\n",
        "\n",
        "    movie_indices = [movies[movies['name'] == movie].index[0] for movie in combined_recommendations.keys()]\n",
        "    if movie_indices:\n",
        "        movie_features = cbf_model_input_scaled[movie_indices]\n",
        "        model_scores = model.predict(movie_features).flatten()\n",
        "\n",
        "        for movie, model_score in zip(combined_recommendations.keys(), model_scores):\n",
        "            combined_recommendations[movie] += weight_model * model_score\n",
        "\n",
        "    filtered_recommendations = {movie: score for movie, score in combined_recommendations.items()\n",
        "                                if movies.loc[movies['name'] == movie, 'star_avg'].values[0] >= 3.3}\n",
        "\n",
        "    final_recommendations = sorted(filtered_recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [movie for movie, _ in final_recommendations[:top_n]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAlEwwEYJOxQ"
      },
      "outputs": [],
      "source": [
        "# 예시 사용자 입력 데이터\n",
        "new_user_mbti = \"INTP\"\n",
        "new_user_preferred_movies = [\"해리포터와 불의 잔\", \"스파이더맨: 노 웨이 홈\"]\n",
        "\n",
        "# 예시 사용자 임베딩 생성 (MBTI 임베딩 사용)\n",
        "new_user_embedding = mbti_embeddings_dict[new_user_mbti]\n",
        "\n",
        "# 최적화된 결합 추천 시스템 실행\n",
        "optimized_recommendations = recommend_movies_combined_optimized(new_user_embedding, new_user_preferred_movies, movie_embeddings_dict, best_gbm)\n",
        "print(\"최적화된 결합 추천 영화 목록:\", optimized_recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labse_model = keras.models.load_model(\"resource/labse_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Rr8ecHJpiL"
      },
      "source": [
        "**모델 저장 및 로드**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY-q7w5xJspz"
      },
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "import joblib\n",
        "\n",
        "joblib.dump(best_gbm, '/content/best_gbm_model.pkl')\n",
        "labse_model.save('/content/labse_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzMRXiEHKFY9"
      },
      "outputs": [],
      "source": [
        "# import joblib\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Gradient Boosting Regressor 모델 불러오기\n",
        "# best_gbm = joblib.load('/content/best_gbm_model.pkl')\n",
        "\n",
        "# # TensorFlow LaBSE 모델 불러오기\n",
        "# labse_model = tf.keras.models.load_model('/content/labse_model.h5', custom_objects={'KerasLayer': hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwrS7wX_7GG7"
      },
      "source": [
        "**추천 목록을 제공받고 좋아하는 콘텐츠 기반으로 재추천하는 로직**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY8vMdwn61Ql"
      },
      "outputs": [],
      "source": [
        "# 재추천 시스템\n",
        "def recommend_movies_combined_excluding(user_embedding, preferred_movies, previous_recommendations, initial_preferred_movies, movie_embeddings_dict, model,\n",
        "                                        weight_mbti=0.4, weight_similar=0.5, weight_model=0.1, top_n=20):\n",
        "    mbti_recommendations = recommend_movies_by_mbti(user_embedding, movie_embeddings_dict, top_n=100)\n",
        "    similar_movie_recommendations = recommend_similar_movies(preferred_movies, movie_embeddings_dict, top_n=100)\n",
        "\n",
        "    combined_recommendations = {}\n",
        "\n",
        "    for movie, score in mbti_recommendations:\n",
        "        if movie not in previous_recommendations and movie not in preferred_movies and movie not in initial_preferred_movies:\n",
        "            if movie not in combined_recommendations:\n",
        "                combined_recommendations[movie] = 0\n",
        "            combined_recommendations[movie] += weight_mbti * score\n",
        "\n",
        "    for movie, score in similar_movie_recommendations:\n",
        "        if movie not in previous_recommendations and movie not in preferred_movies and movie not in initial_preferred_movies:\n",
        "            if movie not in combined_recommendations:\n",
        "                combined_recommendations[movie] = 0\n",
        "            combined_recommendations[movie] += weight_similar * score\n",
        "\n",
        "    movie_indices = [movies[movies['name'] == movie].index[0] for movie in combined_recommendations.keys() if movie not in previous_recommendations and movie not in preferred_movies and movie not in initial_preferred_movies]\n",
        "    if movie_indices:\n",
        "        movie_features = cbf_model_input_scaled[movie_indices]\n",
        "        model_scores = model.predict(movie_features).flatten()\n",
        "\n",
        "        for movie, model_score in zip(combined_recommendations.keys(), model_scores):\n",
        "            if movie not in previous_recommendations and movie not in preferred_movies and movie not in initial_preferred_movies:\n",
        "                combined_recommendations[movie] += weight_model * model_score\n",
        "\n",
        "    filtered_recommendations = {movie: score for movie, score in combined_recommendations.items()\n",
        "                                if movie not in previous_recommendations and movie not in preferred_movies and movie not in initial_preferred_movies and movies.loc[movies['name'] == movie, 'star_avg'].values[0] >= 3.3}\n",
        "\n",
        "    final_recommendations = sorted(filtered_recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [movie for movie, _ in final_recommendations[:top_n]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdjlTfAZ7y-6"
      },
      "outputs": [],
      "source": [
        "# 첫 번째 추천 실행\n",
        "new_user_mbti = \"INFP\"\n",
        "new_user_preferred_movies = [\"어바웃 타임\", \"라라랜드\", \"이터널 선샤인\"]\n",
        "\n",
        "# 예시 사용자 임베딩 생성 (MBTI 임베딩 사용)\n",
        "new_user_embedding = mbti_embeddings_dict[new_user_mbti]\n",
        "first_recommendations = recommend_movies_combined(new_user_embedding, new_user_preferred_movies, movie_embeddings_dict, best_gbm)\n",
        "print(\"첫 번째 추천 영화 목록:\", first_recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sz-rtOs70o6"
      },
      "outputs": [],
      "source": [
        "# 첫 번째 추천으로부터 재추천\n",
        "liked_movies_input = input(\"첫 번째 추천 목록에서 선호하는 영화를 쉼표로 구분하여 입력하세요: \")\n",
        "liked_movies = [movie.strip() for movie in liked_movies_input.split(',')]\n",
        "\n",
        "previous_recommendations = first_recommendations\n",
        "new_preferred_movies = liked_movies  # 사용자 입력을 기반으로 새로운 선호 영화 목록 생성\n",
        "\n",
        "second_recommendations = recommend_movies_combined_excluding(new_user_embedding, new_preferred_movies, previous_recommendations, new_user_preferred_movies, movie_embeddings_dict, best_gbm)\n",
        "print(\"재추천 영화 목록:\", second_recommendations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
